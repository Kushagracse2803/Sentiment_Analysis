{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa06a45c-9b68-4865-9a5a-520e479245da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69668b32-02de-4b8e-8d23-f938aeae8c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7eac790-df65-4f4e-8bf5-6f152e2b1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b75be-cc56-4726-912e-72d93aa28201",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk scikit-learn pandas tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d6fca2-48ad-48a7-8248-74242cc16317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, SpatialDropout1D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 255)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae5362-5751-4c8c-acc4-3fc7f4b4fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# # ‚úÖ Use tensorflow.keras instead of keras\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, SpatialDropout1D\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing import sequence\n",
    "# from tensorflow.keras.utils import to_categorical, pad_sequences\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# # Pandas display options\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_colwidth', 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c4f1e2-5cd5-4782-aeef-8d4478ee6e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.13.1\n",
      "Uninstalling tensorflow-2.13.1:\n",
      "  Successfully uninstalled tensorflow-2.13.1\n",
      "Found existing installation: tensorflow-intel 2.13.1\n",
      "Uninstalling tensorflow-intel-2.13.1:\n",
      "  Successfully uninstalled tensorflow-intel-2.13.1\n",
      "Found existing installation: keras 2.13.1\n",
      "Uninstalling keras-2.13.1:\n",
      "  Successfully uninstalled keras-2.13.1\n",
      "Found existing installation: tensorflow-estimator 2.13.0\n",
      "Uninstalling tensorflow-estimator-2.13.0:\n",
      "  Successfully uninstalled tensorflow-estimator-2.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping tensorflow-cpu as it is not installed.\n",
      "WARNING: Skipping keras-nightly as it is not installed.\n",
      "WARNING: Skipping tf-nightly as it is not installed.\n",
      "WARNING: Skipping tb-nightly as it is not installed.\n",
      "WARNING: Skipping tf-estimator-nightly as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 88 (304.2 MB)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tensorflow tensorflow-cpu tensorflow-intel keras keras-nightly \\\n",
    "tf-nightly tb-nightly tf-estimator-nightly tensorflow-estimator\n",
    "!pip cache purge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d8a769-c8a5-45b6-b2e8-d07ffb1234fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.13.1\n",
      "  Downloading tensorflow-2.13.1-cp310-cp310-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-intel==2.13.1 (from tensorflow==2.13.1)\n",
      "  Downloading tensorflow_intel-2.13.1-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (4.25.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (76.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (3.1.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.1->tensorflow==2.13.1)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (1.73.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (2.13.0)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-intel==2.13.1->tensorflow==2.13.1)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.1->tensorflow==2.13.1)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow==2.13.1) (0.31.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (3.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (3.0.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (0.45.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (2024.6.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kushagra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow==2.13.1) (2.1.5)\n",
      "Downloading tensorflow-2.13.1-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Downloading tensorflow_intel-2.13.1-cp310-cp310-win_amd64.whl (276.5 MB)\n",
      "   ---------------------------------------- 0.0/276.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/276.5 MB 3.4 MB/s eta 0:01:23\n",
      "   ---------------------------------------- 2.1/276.5 MB 6.2 MB/s eta 0:00:45\n",
      "    --------------------------------------- 3.9/276.5 MB 7.1 MB/s eta 0:00:39\n",
      "    --------------------------------------- 6.0/276.5 MB 8.0 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 8.7/276.5 MB 9.1 MB/s eta 0:00:30\n",
      "   - -------------------------------------- 11.8/276.5 MB 10.3 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 16.5/276.5 MB 12.2 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 20.2/276.5 MB 13.0 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 26.2/276.5 MB 15.0 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 32.5/276.5 MB 16.8 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 38.5/276.5 MB 17.9 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 47.2/276.5 MB 20.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 56.1/276.5 MB 21.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 65.0/276.5 MB 23.5 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 69.5/276.5 MB 23.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 70.3/276.5 MB 23.4 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 74.7/276.5 MB 22.0 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 78.1/276.5 MB 21.7 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 86.8/276.5 MB 22.8 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 92.5/276.5 MB 23.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 97.0/276.5 MB 22.8 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 105.4/276.5 MB 23.7 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 113.5/276.5 MB 24.4 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 120.8/276.5 MB 24.9 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 124.5/276.5 MB 24.7 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 131.3/276.5 MB 24.9 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 138.4/276.5 MB 25.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 143.1/276.5 MB 25.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 148.6/276.5 MB 25.3 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 155.2/276.5 MB 25.4 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 161.2/276.5 MB 25.6 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 170.1/276.5 MB 26.1 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 175.1/276.5 MB 26.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 184.5/276.5 MB 26.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 191.4/276.5 MB 26.8 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 196.1/276.5 MB 27.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 201.9/276.5 MB 26.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 207.9/276.5 MB 26.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 211.8/276.5 MB 26.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 215.7/276.5 MB 26.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 221.0/276.5 MB 26.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 226.5/276.5 MB 26.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 233.6/276.5 MB 26.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 238.6/276.5 MB 26.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 244.8/276.5 MB 26.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 249.6/276.5 MB 26.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 255.1/276.5 MB 26.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 262.7/276.5 MB 26.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  269.7/276.5 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  274.2/276.5 MB 28.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.3/276.5 MB 28.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.3/276.5 MB 28.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.3/276.5 MB 28.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.3/276.5 MB 28.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 276.5/276.5 MB 26.3 MB/s  0:00:11\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 30.7 MB/s  0:00:00\n",
      "Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: typing-extensions, tensorflow-estimator, keras, tensorflow-intel, tensorflow\n",
      "\n",
      "  Attempting uninstall: typing-extensions\n",
      "\n",
      "    Found existing installation: typing_extensions 4.14.1\n",
      "\n",
      "    Uninstalling typing_extensions-4.14.1:\n",
      "\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.14.1\n",
      "   ---------------------------------------- 0/5 [typing-extensions]\n",
      "   -------- ------------------------------- 1/5 [tensorflow-estimator]\n",
      "   -------- ------------------------------- 1/5 [tensorflow-estimator]\n",
      "   -------- ------------------------------- 1/5 [tensorflow-estimator]\n",
      "   -------- ------------------------------- 1/5 [tensorflow-estimator]\n",
      "   -------- ------------------------------- 1/5 [tensorflow-estimator]\n",
      "   -------- ------------------------------- 1/5 [tensorflow-estimator]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ---------------- ----------------------- 2/5 [keras]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ------------------------ --------------- 3/5 [tensorflow-intel]\n",
      "   ---------------------------------------- 5/5 [tensorflow]\n",
      "\n",
      "Successfully installed keras-2.13.1 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.1 typing-extensions-4.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 8.28.0 requires typing-extensions>=4.6; python_version < \"3.12\", but you have typing-extensions 4.5.0 which is incompatible.\n",
      "langchain-core 0.3.68 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "langchain-google-genai 2.1.7 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
      "openai 1.95.1 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "optree 0.17.0 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic 2.11.3 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.33.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "sqlalchemy 2.0.41 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
      "torch 2.7.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "typing-inspection 0.4.0 requires typing-extensions>=4.12.0, but you have typing-extensions 4.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Option A (common stable choice for Py 3.10)\n",
    "!pip install \"tensorflow==2.13.1\"\n",
    "\n",
    "# Option B (newer, if A doesn‚Äôt work on your machine)\n",
    "# pip install \"tensorflow==2.15.0\"\n",
    "\n",
    "# Option C (CPU-only explicit build)\n",
    "# pip install \"tensorflow-cpu==2.13.1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e4819e-8d4b-49e7-95ef-020a37cc3b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kushagra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    " import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ‚úÖ Use tensorflow.keras instead of keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical, pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 255)\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c836d247-8a0e-4a11-ae61-e338ecd56282",
   "metadata": {},
   "source": [
    "text\n",
    "# üìò Imports Used in NLP + Deep Learning Project\n",
    "\n",
    "Let's quickly understand **what each import is doing** in our workflow:\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Text Preprocessing (NLTK)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "text\n",
    "- **NLTK (Natural Language Toolkit)** helps in text cleaning.  \n",
    "- `stopwords` = removes common words like *is, the, and* that don‚Äôt add meaning.  \n",
    "\n",
    "---\n",
    "\n",
    "### üìä Data Handling (Pandas)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 255)\n",
    "\n",
    "text\n",
    "- **Pandas** for loading, exploring datasets.  \n",
    "- Display options = easier to view full rows/columns in the output.  \n",
    "\n",
    "---\n",
    "\n",
    "### üî¨ Machine Learning Utilities (Scikit-learn)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "text\n",
    "- `train_test_split` ‚Üí split dataset into **train/test parts**.  \n",
    "- `CountVectorizer` ‚Üí converts text into word counts.  \n",
    "- `TfidfTransformer` ‚Üí converts counts into **TF‚ÄëIDF weights**.  \n",
    "- `confusion_matrix` ‚Üí evaluation metric for classification outcomes.  \n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ Deep Learning (TensorFlow + Keras)\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical, pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "text\n",
    "- **Keras (inside TensorFlow)** ‚Üí for building neural networks.  \n",
    "- Layers:\n",
    "  - `Embedding` ‚Üí converts words into vector representations.  \n",
    "  - `LSTM` ‚Üí remembers context in text sequences (good for NLP).  \n",
    "  - `Dense, Dropout` ‚Üí output + regularization layers.  \n",
    "- `Tokenizer` / `pad_sequences` ‚Üí prepare text for model input.  \n",
    "- `RMSprop` ‚Üí optimizer to adjust weights.  \n",
    "- `EarlyStopping`, `ModelCheckpoint` ‚Üí stop training early & save the best model.  \n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Together, these libraries allow us to:  \n",
    "1. **Clean & preprocess text** (NLTK)  \n",
    "2. **Prepare datasets & features** (Pandas + Scikit-learn)  \n",
    "3. **Build & train deep learning models** (TensorFlow/Keras)  \n",
    "4. **Evaluate performance** (confusion matrix, metrics)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20af9b6c-4f67-4699-b29a-f1e6ded3c2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen-...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                           review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of v...   \n",
       "1  A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen-...   \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well b...   \n",
       "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situ...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fb78e46-d28f-433c-8fd3-c335a3eaa98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "633507db-8c95-45b5-a569-5cfc2e9b23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d118755-e3a4-4240-bca0-510f08faf5c6",
   "metadata": {},
   "source": [
    "#üîπ Explanation\n",
    "df ‚Üí your Pandas DataFrame.\n",
    "\n",
    ".iloc ‚Üí integer-location based indexing (it selects rows/columns by their numeric position, not labels).\n",
    "\n",
    ":10000 ‚Üí means from start (0) up to, but not including, index 10000.\n",
    "\n",
    "Equivalent to df[0:10000].\n",
    "\n",
    "So this line says:\n",
    "üëâ ‚ÄúTake only the first 10,000 rows of df and assign it back to df.‚Äù\n",
    "\n",
    "üîπ Why Do People Use This?\n",
    "Large dataset handling\n",
    "\n",
    "If dataset has millions of rows, training/testing may be slow.\n",
    "\n",
    "Restricting to first 10,000 rows makes experiments faster.\n",
    "\n",
    "Debugging\n",
    "\n",
    "Try on a smaller subset before running on full dataset.\n",
    "\n",
    "Memory issues\n",
    "\n",
    "Keep kernel from crashing due to RAM overload.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "185f0332-8055-4596-b108-247da9ee2a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of v...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen-...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                           review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of v...   \n",
       "1  A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen-...   \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well b...   \n",
       "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situ...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8a0eddb-c4d1-4d35-a007-7ebba388a086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44346a5b-d8b1-4e8d-abc6-597ba17790ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "454a5039-ecd6-4a4c-88e4-187a9189f934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    5028\n",
       "negative    4972\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11b66105-d623-4e9c-8d97-1e18f767088b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64108354-8b97-4729-97b6-c09ed608be8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1c25a2d-89bd-4221-a0b4-89a9f57279ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd11eefb-4b11-4f5c-902a-a6c461500cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bffb0d-6b85-4120-bc4a-41cd54307b31",
   "metadata": {},
   "source": [
    "# Basic Preprocessing\n",
    "1. Remove tags-HTML\n",
    "2. Lower case\n",
    "3. Remove stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4795d0ff-0568-4299-a1a4-ee6b3cf7b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_tags(raw_text):\n",
    "    cleaned_text=re.sub(re.compile('<.*?>'),'',raw_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b95a053-ac9d-431c-9222-a0777dc07311",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84011662-2112-4710-acd1-2cee3012f70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence, whi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well b...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.OK, first of al...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                           review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence, whi...   \n",
       "1  A wonderful little production. The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. The actors are extremely well chosen- Michael Sheen not only ...   \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well b...   \n",
       "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.OK, first of al...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situ...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4781863-9351-41fb-aaf1-abb720126d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b6780f9-3520-4d67-8bf0-0c601cfdfd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04fb6685-4200-48c7-920a-48d105b640b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. forget pretty pictures painted for mainstream audiences, forget charm, forget romance...oz doesn't mess around. the first episode i ever saw struck me as so nasty it was surreal, i couldn't say i was ready for it, but as i watched more, i developed a taste for oz, and got accustomed to the high levels of graphic violence. not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) watching oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8fb35fc-ebe3-4c73-834e-afd7866b319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kushagra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "sw_list=stopwords.words('english')\n",
    "\n",
    "df['review']=df['review'].apply(lambda x:[item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8838b759-b424-4cae-99da-c3cf470cdfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one reviewers mentioned watching 1 oz episode hooked. right, exactly happened me.the first thing struck oz brutality unflinching scenes violence, set right word go. trust me, show faint hearted timid. show pulls punches regards drugs, sex violence. hardcore, classic use word.it called oz nickname given oswald maximum security state penitentary. focuses mainly emerald city, experimental section prison cells glass fronts face inwards, privacy high agenda. em city home many..aryans, muslims, gangstas, latinos, christians, italians, irish more....so scuffles, death stares, dodgy dealings shady agreements never far away.i would say main appeal show due fact goes shows dare. forget pretty pictures painted mainstream audiences, forget charm, forget romance...oz mess around. first episode ever saw struck nasty surreal, say ready it, watched more, developed taste oz, got accustomed high levels graphic violence. violence, injustice (crooked guards who'll sold nickel, inmates who'll kill order get away it, well mannered, middle class inmates turned prison bitches due lack street skills prison experience) watching oz, may become comfortable uncomfortable viewing....thats get touch darker side.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ef8ea90-2232-4aa4-98bb-97ab45c25dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode hooked. right, exactly happened me.the first thing struck oz brutality unflinching scenes violence, set right word go. trust me, show faint hearted timid. show pulls punches regards drugs, sex violence. ha...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production. filming technique unassuming- old-time-bbc fashion gives comforting, sometimes discomforting, sense realism entire piece. actors extremely well chosen- michael sheen \"has got polari\" voices pat too! truly see seamless edit...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer weekend, sitting air conditioned theater watching light-hearted comedy. plot simplistic, dialogue witty characters likable (even well bread suspected serial killer). may disappointed realize match point 2: r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's family little boy (jake) thinks there's zombie closet &amp; parents fighting time.this movie slower soap opera... suddenly, jake decides become rambo kill zombie.ok, first going make film must decide thriller drama! drama movie watchable...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love time money\" visually stunning film watch. mr. mattei offers us vivid portrait human relations. movie seems telling us money, power success people different situations encounter. variation arthur schnitzler's play theme, director ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                           review  \\\n",
       "0  one reviewers mentioned watching 1 oz episode hooked. right, exactly happened me.the first thing struck oz brutality unflinching scenes violence, set right word go. trust me, show faint hearted timid. show pulls punches regards drugs, sex violence. ha...   \n",
       "1  wonderful little production. filming technique unassuming- old-time-bbc fashion gives comforting, sometimes discomforting, sense realism entire piece. actors extremely well chosen- michael sheen \"has got polari\" voices pat too! truly see seamless edit...   \n",
       "2  thought wonderful way spend time hot summer weekend, sitting air conditioned theater watching light-hearted comedy. plot simplistic, dialogue witty characters likable (even well bread suspected serial killer). may disappointed realize match point 2: r...   \n",
       "3  basically there's family little boy (jake) thinks there's zombie closet & parents fighting time.this movie slower soap opera... suddenly, jake decides become rambo kill zombie.ok, first going make film must decide thriller drama! drama movie watchable...   \n",
       "4  petter mattei's \"love time money\" visually stunning film watch. mr. mattei offers us vivid portrait human relations. movie seems telling us money, power success people different situations encounter. variation arthur schnitzler's play theme, director ...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e19ee8a7-f24a-4698-a8bc-9b4c04c85fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:1]\n",
    "y=df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35d129e8-14aa-40bf-b5f5-0f1213ca2bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode hooked. right, exactly happened me.the first thing struck oz brutality unflinching scenes violence, set right word go. trust me, show faint hearted timid. show pulls punches regards drugs, sex violence. ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production. filming technique unassuming- old-time-bbc fashion gives comforting, sometimes discomforting, sense realism entire piece. actors extremely well chosen- michael sheen \"has got polari\" voices pat too! truly see seamless edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer weekend, sitting air conditioned theater watching light-hearted comedy. plot simplistic, dialogue witty characters likable (even well bread suspected serial killer). may disappointed realize match point 2: r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's family little boy (jake) thinks there's zombie closet &amp; parents fighting time.this movie slower soap opera... suddenly, jake decides become rambo kill zombie.ok, first going make film must decide thriller drama! drama movie watchable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love time money\" visually stunning film watch. mr. mattei offers us vivid portrait human relations. movie seems telling us money, power success people different situations encounter. variation arthur schnitzler's play theme, director ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                           review\n",
       "0  one reviewers mentioned watching 1 oz episode hooked. right, exactly happened me.the first thing struck oz brutality unflinching scenes violence, set right word go. trust me, show faint hearted timid. show pulls punches regards drugs, sex violence. ha...\n",
       "1  wonderful little production. filming technique unassuming- old-time-bbc fashion gives comforting, sometimes discomforting, sense realism entire piece. actors extremely well chosen- michael sheen \"has got polari\" voices pat too! truly see seamless edit...\n",
       "2  thought wonderful way spend time hot summer weekend, sitting air conditioned theater watching light-hearted comedy. plot simplistic, dialogue witty characters likable (even well bread suspected serial killer). may disappointed realize match point 2: r...\n",
       "3  basically there's family little boy (jake) thinks there's zombie closet & parents fighting time.this movie slower soap opera... suddenly, jake decides become rambo kill zombie.ok, first going make film must decide thriller drama! drama movie watchable...\n",
       "4  petter mattei's \"love time money\" visually stunning film watch. mr. mattei offers us vivid portrait human relations. movie seems telling us money, power success people different situations encounter. variation arthur schnitzler's play theme, director ..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb393f0f-1266-492d-9049-82997db30b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder=LabelEncoder()\n",
    "\n",
    "y=encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a9092-e402-4945-a70a-400e2b5f8533",
   "metadata": {},
   "source": [
    "### üîπ What is LabelEncoder?\n",
    "LabelEncoder is used to convert categorical labels (strings) into numeric values (integers).\n",
    "\n",
    "Machine Learning / Deep Learning models cannot understand text labels directly ‚Äì they require numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f97e3a68-701b-43aa-8812-c39b77b4e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca5d2633-0aaa-48d7-b0cf-a730be04e5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7986, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae8198db-aefb-4aea-9a33-741f9d39f1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1997, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c08aa-4542-4ee5-b575-85c5f2819c54",
   "metadata": {},
   "source": [
    "### APPLY BOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46047b67-3015-4143-9319-34e290280ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d7475bc-a23a-4905-97c9-8e532a4de9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow=cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow=cv.transform(X_test['review']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c1e1a-4cfb-4143-98b3-3c82f78d3616",
   "metadata": {},
   "source": [
    "### üìò Bag of Words (BoW) Representation\n",
    "\n",
    "We are using `CountVectorizer` (`cv`) to convert raw text reviews into a numerical representation.\n",
    "\n",
    "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow = cv.transform(X_test['review']).toarray()\n",
    "\n",
    "text\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ Step by Step\n",
    "\n",
    "1. **`cv.fit_transform(X_train['review'])`**\n",
    "   - **`fit`** ‚Üí learns the vocabulary (unique words) **only from the training data**.\n",
    "   - **`transform`** ‚Üí converts each review into a **vector of word counts** based on that vocabulary.\n",
    "   - **`.toarray()`** ‚Üí converts the sparse matrix into a dense NumPy array for easier handling.\n",
    "\n",
    "   üëâ So, `X_train_bow` becomes a **matrix** where:\n",
    "   - Rows = reviews\n",
    "   - Columns = words in vocabulary\n",
    "   - Values = frequency of each word in each review.\n",
    "\n",
    "---\n",
    "\n",
    "2. **`cv.transform(X_test['review'])`**\n",
    "   - Here, we use **only `transform`** because the vocabulary is already learned from training data.\n",
    "   - Converts test reviews into the **same feature space** (same word indices as training).\n",
    "   - **Important**: We don‚Äôt call `fit` again on test data ‚Üí prevents **data leakage**.\n",
    "\n",
    "   üëâ So, `X_test_bow` = numerical vectorized version of test reviews.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ Example\n",
    "\n",
    "Suppose `X_train['review']` =  \n",
    "- \"I love NLP\"\n",
    "- \"I love Python\"\n",
    "\n",
    "`cv.fit_transform` builds vocabulary = { \"I\", \"love\", \"NLP\", \"Python\" }\n",
    "\n",
    "Vectors:  \n",
    "- \"I love NLP\" ‚Üí [1, 1, 1, 0]  \n",
    "- \"I love Python\" ‚Üí [1, 1, 0, 1]  \n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **In summary:**  \n",
    "- `X_train_bow` = training reviews ‚Üí word count vectors  \n",
    "- `X_test_bow` = test reviews ‚Üí word count vectors (using same vocabulary)  \n",
    "- This gives us numeric **X features** to train/test ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a4d9a9e-1a34-4b44-80a4-868bace8b097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b7965ec-1878-42fc-825d-daf92b295309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB()\n",
    "\n",
    "gnb.fit(X_train_bow,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7941a6-3ea4-4bec-b727-99890a373fab",
   "metadata": {},
   "source": [
    "### ü§ñ Naive Bayes for Sentiment Analysis\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_bow, y_train)\n",
    "\n",
    "text\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ What‚Äôs happening here?\n",
    "\n",
    "1. **`GaussianNB()`**\n",
    "   - We are creating a **Naive Bayes classifier** model.  \n",
    "   - Specifically, **Gaussian Naive Bayes (GNB)** assumes that features follow a **normal distribution**.  \n",
    "   - It‚Äôs simple, fast, and often works well for text classification.\n",
    "\n",
    "2. **`gnb.fit(X_train_bow, y_train)`**\n",
    "   - `X_train_bow` ‚Üí our training features (reviews turned into numeric vectors using Bag of Words).  \n",
    "   - `y_train` ‚Üí target labels (e.g., `positive`, `negative`, `neutral`, encoded as numbers).  \n",
    "   - The model **learns the probability distributions** of words (features) with respect to each sentiment class.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ Why use Naive Bayes here?\n",
    "- **Efficient for text data** (Bag of Words produces large, sparse data ‚Üí NB handles this well).  \n",
    "- Often a **good baseline model** for sentiment analysis before trying deep learning (like LSTM).  \n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ In short:  \n",
    "We are **training a Naive Bayes model** on Bag of Words features (`X_train_bow`) with sentiment labels (`y_train`) so that it can learn to **predict the sentiment of new reviews**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4afcc2d-dba7-48bf-a669-1035a5aa2a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6324486730095142"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=gnb.predict(X_test_bow)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2aa74112-7250-413d-8871-85e7eb0e4f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[717, 235],\n",
       "       [499, 546]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c10b6a5-9ba1-4d0b-b1ea-871a2f32c7c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2cbab557-4451-4e5b-b5f3-d50b8a6d8a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8407611417125689"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow,y_train)\n",
    "\n",
    "y_pred=rf.predict(X_test_bow)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e48d389c-26f0-482f-a287-2971da74209e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.87 GiB for an array with shape (7986, 48282) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      4\u001b[0m svm \u001b[38;5;241m=\u001b[39m LinearSVC()\n\u001b[1;32m----> 5\u001b[0m \u001b[43msvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_bow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mpredict(X_test_bow)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, y_pred))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_classes.py:305\u001b[0m, in \u001b[0;36mLinearSVC.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    282\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03m        An instance of the estimator.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    837\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 839\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.87 GiB for an array with shape (7986, 48282) and data type float64"
     ]
    }
   ],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# svm = LinearSVC()\n",
    "# svm.fit(X_train_bow, y_train)\n",
    "# y_pred = svm.predict(X_test_bow)\n",
    "\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5377df4-eb24-4f30-82b9-c0b1a333af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# svm = LinearSVC(dual=False, max_iter=2000)  \n",
    "# svm.fit(X_train_bow, y_train)\n",
    "# y_pred = svm.predict(X_test_bow)\n",
    "\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a05794-46e1-4a59-b493-526f917dfcba",
   "metadata": {},
   "source": [
    "### ‚ùå Disadvantages of SVM\n",
    "1. High Memory & Computation Cost\n",
    "SVMs are not very efficient on large datasets (many samples or features).\n",
    "\n",
    "Training time can be very slow when you have thousands of rows √ó tens of thousands of features (like BoW/TF‚ÄëIDF).\n",
    "\n",
    "This is why you hit MemoryError in your case.\n",
    "\n",
    "2. Not Great with Very Large Feature Spaces (unless LinearSVC)\n",
    "Standard SVC internally densifies the matrix ‚Üí crashes on sparse BoW data.\n",
    "\n",
    "For text (where vocab = 20k‚Äì100k), you need LinearSVC, otherwise RAM explodes.\n",
    "\n",
    "3. Choice of Kernel is Tricky\n",
    "Kernel selection (linear, rbf, poly, sigmoid) greatly influences performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771615f-f56f-4b74-a73d-f43c43289f09",
   "metadata": {},
   "source": [
    "# N Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "144404a9-adc2-488b-be55-e8e62cdbf276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8407611417125689"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2),max_features=5000)\n",
    "X_train_bow=cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow=cv.transform(X_test['review']).toarray()\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_bow,y_train)\n",
    "y_pred=rf.predict(X_test_bow)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088686a8-3cb7-49d0-9144-859e665b6936",
   "metadata": {},
   "source": [
    "### TFIDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9fca4f82-0936-4fd8-a5b1-1578e54de55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dab09417-a661-4e64-87ec-007ee2d7cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train['review'])\n",
    "X_test_tfidf = tfidf.transform(X_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2cbcfb24-c101-4cbf-81c5-6d2dcbe7b9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8402603905858789"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_tfidf,y_train)\n",
    "y_pred = rf.predict(X_test_tfidf)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381288b-e933-42bf-9b28-88fb4f2827a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
